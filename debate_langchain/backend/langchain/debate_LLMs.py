
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SequentialChain
import os

# ğŸ” OpenAI API í‚¤ ì„¤ì •
from dotenv import load_dotenv
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")


# ğŸ’¡ ì£¼ì œì™€ ë¼ìš´ë“œ ì„¤ì •
TOPIC = "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì°½ì˜ì„±ì„ ë„˜ì–´ì„¤ ìˆ˜ ìˆëŠ”ê°€?"
NUM_ROUNDS = 2
NUM_DEBATERS = 3

# ğŸ™ï¸ í† ë¡ ì í”„ë¡¬í”„íŠ¸
debater_prompt = PromptTemplate(
    input_variables=["topic", "chat_history"],
    template="""
ë‹¹ì‹ ì€ ì—´ì •ì ì¸ í† ë¡ ìì…ë‹ˆë‹¤.
ì£¼ì œ: "{topic}"
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”:
{chat_history}

ë‹¹ì‹ ì˜ ì…ì¥ì„ ë§í•´ì£¼ì„¸ìš”.
"""
)

# âš–ï¸ ì¤‘ì¬ì í”„ë¡¬í”„íŠ¸
moderator_prompt = PromptTemplate(
    input_variables=["topic", "chat_history"],
    template="""
ë‹¹ì‹ ì€ ì¤‘ë¦½ì ì¸ ì¤‘ì¬ìì…ë‹ˆë‹¤.
ì£¼ì œ: "{topic}"
ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡ :
{chat_history}

ê°„ëµí•˜ê²Œ ìš”ì•½í•˜ê³  ë‹¤ìŒ ë°œì–¸ìë¥¼ ì§€ëª©í•´ì£¼ì„¸ìš”.
"""
)

# ğŸ¤– GPT-4 í† ë¡ ì êµ¬ì„±
temperatures = [0.6, 0.65, 0.7]
debater_chains = []
for i in range(NUM_DEBATERS):
    llm = ChatOpenAI(model_name="gpt-4", temperature=temperatures[i], openai_api_key=openai_api_key)
    memory = ConversationBufferMemory(return_messages=True, memory_key="chat_history")
    chain = LLMChain(llm=llm, prompt=debater_prompt, memory=memory, verbose=False)
    debater_chains.append(chain)

# ğŸ§‘â€âš–ï¸ ì¤‘ì¬ì êµ¬ì„±
moderator_llm = ChatOpenAI(model_name="gpt-4", temperature=0.3, openai_api_key=openai_api_key)
moderator_memory = ConversationBufferMemory(return_messages=True, memory_key="chat_history")
moderator_chain = LLMChain(
    llm=moderator_llm, prompt=moderator_prompt, memory=moderator_memory, verbose=False
)

# ğŸ í† ë¡  ì‹¤í–‰
print(f"ğŸ’¬ ì£¼ì œ: {TOPIC}\n")

for round_num in range(NUM_ROUNDS):
    print(f"ğŸ” Round {round_num + 1}")
    for i, chain in enumerate(debater_chains):
        response = chain.run(topic=TOPIC)
        print(f"[í† ë¡ ì {i+1}] {response}\n")
        moderator_memory.chat_memory.add_user_message(f"[í† ë¡ ì {i+1}] {response}")

    mod_response = moderator_chain.run(topic=TOPIC)
    print(f"[ì¤‘ì¬ì] {mod_response}\n")
